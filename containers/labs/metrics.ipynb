{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Investigating the different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# scoot functions\n",
    "from cleanair.scoot import (\n",
    "    generate_fp,\n",
    "    load_model_from_file,\n",
    "    load_processed_data_from_file,\n",
    "    load_scoot_df,\n",
    "    plotly_results,\n",
    "    percentage_coverage,\n",
    "    sample_intensity,\n",
    "    sample_n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup global params\n",
    "experiment = \"daily\"\n",
    "\n",
    "user_settings_fp = os.path.join(\"..\", \"..\", \"terraform\", \".secrets\", \"user_settings.json\")\n",
    "with open(user_settings_fp) as json_file:\n",
    "    user_settings = json.load(json_file)\n",
    "root = user_settings[\"root\"]\n",
    "\n",
    "# get the settings for kernels and scoot data\n",
    "with open(os.path.join(root, experiment, \"settings\", \"kernel_settings.json\")) as kernel_file:\n",
    "    kernel_settings = json.load(kernel_file)\n",
    "with open(os.path.join(root, experiment, \"settings\", \"data_settings.json\")) as scoot_file:\n",
    "    data_settings = json.load(scoot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of normal/lockdown\n",
    "\n",
    "Provide change in traffic for normal vs previous day and lockdown vs previous day.\n",
    "\n",
    "1. Take the total traffic on a normal/lockdown Monday.\n",
    "2. Take the total traffic of the most recent Monday.\n",
    "3. Remove outliers from this detector (e.g. $\\mu \\pm 3\\sigma$).\n",
    "4. Calculate the percentage change in total traffic from (1) to (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at just one day\n",
    "normal_day = \"2020-02-10T00:00:00\"     # a normal day\n",
    "lockdown_day = \"2020-03-23T00:00:00\"   # a normal lockdown day \n",
    "latest_day = \"2020-03-30T00:00:00\"     # the most recent day\n",
    "\n",
    "# load data for these day\n",
    "normal_df = load_scoot_df(\n",
    "    root=root,\n",
    "    experiment=experiment,\n",
    "    timestamp=normal_day,\n",
    "    filename=\"scoot\"\n",
    ")\n",
    "lockdown_df = load_scoot_df(\n",
    "    root=root,\n",
    "    experiment=experiment,\n",
    "    timestamp=lockdown_day,\n",
    "    filename=\"scoot\"\n",
    ")\n",
    "latest_df = load_scoot_df(\n",
    "    root=root,\n",
    "    experiment=experiment,\n",
    "    timestamp=latest_day,\n",
    "    filename=\"scoot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detector_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N00/002e1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>193.541667</td>\n",
       "      <td>77.388337</td>\n",
       "      <td>61.0</td>\n",
       "      <td>139.00</td>\n",
       "      <td>204.5</td>\n",
       "      <td>254.00</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N00/002g1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>200.458333</td>\n",
       "      <td>71.757429</td>\n",
       "      <td>51.0</td>\n",
       "      <td>164.25</td>\n",
       "      <td>232.0</td>\n",
       "      <td>246.50</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N00/002p1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>356.625000</td>\n",
       "      <td>132.671485</td>\n",
       "      <td>112.0</td>\n",
       "      <td>272.75</td>\n",
       "      <td>420.0</td>\n",
       "      <td>452.50</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N00/003a1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>138.750000</td>\n",
       "      <td>61.089564</td>\n",
       "      <td>29.0</td>\n",
       "      <td>107.25</td>\n",
       "      <td>154.5</td>\n",
       "      <td>185.25</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N00/004b1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>370.958333</td>\n",
       "      <td>146.772666</td>\n",
       "      <td>77.0</td>\n",
       "      <td>296.50</td>\n",
       "      <td>430.0</td>\n",
       "      <td>472.75</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N32/208a2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>794.333333</td>\n",
       "      <td>167.846160</td>\n",
       "      <td>614.0</td>\n",
       "      <td>718.50</td>\n",
       "      <td>823.0</td>\n",
       "      <td>884.50</td>\n",
       "      <td>946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N32/209a1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>584.666667</td>\n",
       "      <td>92.316485</td>\n",
       "      <td>481.0</td>\n",
       "      <td>548.00</td>\n",
       "      <td>615.0</td>\n",
       "      <td>636.50</td>\n",
       "      <td>658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N32/209a2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>130.678996</td>\n",
       "      <td>583.0</td>\n",
       "      <td>678.50</td>\n",
       "      <td>774.0</td>\n",
       "      <td>803.50</td>\n",
       "      <td>833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N32/210a1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>638.333333</td>\n",
       "      <td>125.556096</td>\n",
       "      <td>515.0</td>\n",
       "      <td>574.50</td>\n",
       "      <td>634.0</td>\n",
       "      <td>700.00</td>\n",
       "      <td>766.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N32/210a2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>430.666667</td>\n",
       "      <td>91.882171</td>\n",
       "      <td>331.0</td>\n",
       "      <td>390.00</td>\n",
       "      <td>449.0</td>\n",
       "      <td>480.50</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10077 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std    min     25%    50%     75%  \\\n",
       "detector_id                                                                \n",
       "N00/002e1     24.0  193.541667   77.388337   61.0  139.00  204.5  254.00   \n",
       "N00/002g1     24.0  200.458333   71.757429   51.0  164.25  232.0  246.50   \n",
       "N00/002p1     24.0  356.625000  132.671485  112.0  272.75  420.0  452.50   \n",
       "N00/003a1     24.0  138.750000   61.089564   29.0  107.25  154.5  185.25   \n",
       "N00/004b1     24.0  370.958333  146.772666   77.0  296.50  430.0  472.75   \n",
       "...            ...         ...         ...    ...     ...    ...     ...   \n",
       "N32/208a2      3.0  794.333333  167.846160  614.0  718.50  823.0  884.50   \n",
       "N32/209a1      3.0  584.666667   92.316485  481.0  548.00  615.0  636.50   \n",
       "N32/209a2      3.0  730.000000  130.678996  583.0  678.50  774.0  803.50   \n",
       "N32/210a1      3.0  638.333333  125.556096  515.0  574.50  634.0  700.00   \n",
       "N32/210a2      3.0  430.666667   91.882171  331.0  390.00  449.0  480.50   \n",
       "\n",
       "               max  \n",
       "detector_id         \n",
       "N00/002e1    300.0  \n",
       "N00/002g1    282.0  \n",
       "N00/002p1    498.0  \n",
       "N00/003a1    211.0  \n",
       "N00/004b1    540.0  \n",
       "...            ...  \n",
       "N32/208a2    946.0  \n",
       "N32/209a1    658.0  \n",
       "N32/209a2    833.0  \n",
       "N32/210a1    766.0  \n",
       "N32/210a2    512.0  \n",
       "\n",
       "[10077 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"n_vehicles_in_interval\"\n",
    "\n",
    "# groupby detector\n",
    "normal_gb = normal_df.groupby(\"detector_id\")\n",
    "normal_gb[col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalous detectors: 75\n",
      "Total number of detectors: 10077\n"
     ]
    }
   ],
   "source": [
    "# remove outliers\n",
    "to_remove = []   # list of indices to remove\n",
    "detector_anomalies = []  # list of detectors with anomalies\n",
    "num_sigma = 3\n",
    "\n",
    "for detector_id, group in normal_gb:\n",
    "    remove_in_group = group.index[abs(group[col] - group[col].mean()) > 3 * group[col].std()].tolist()\n",
    "    if remove_in_group:\n",
    "        detector_anomalies.append(detector_id)\n",
    "    to_remove.extend(remove_in_group)\n",
    "print(\"Number of anomalous detectors:\", len(detector_anomalies))\n",
    "print(\"Total number of detectors:\", len(normal_df.detector_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now remove detectors and re-run groupby/stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage coverage\n",
    "\n",
    "Given a confidence interval (90%) over the posterior distribution of our model, then coverage is the proportion of observations (true values) that are contained within the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at just one detector for now\n",
    "detector_id = \"N00/002e1\"\n",
    "kernel_id = \"matern32_ls=0.1_v=0.1\"\n",
    "kwargs = dict(\n",
    "    root=root,\n",
    "    experiment=experiment,\n",
    "    detector_id=detector_id,\n",
    "    kernel_id=kernel_id\n",
    ")\n",
    "# get model, X, Y for normal\n",
    "normal_model = load_model_from_file(timestamp=normal_day, **kwargs)\n",
    "normal_x, normal_y = load_processed_data_from_file(timestamp=normal_day, **kwargs)\n",
    "\n",
    "# get model, X, Y for lockdown\n",
    "# lockdown_model = load_model_from_file(timestamp=lockdown_day, **kwargs)\n",
    "lockdown_x, lockdown_y = load_processed_data_from_file(timestamp=lockdown_day, **kwargs)\n",
    "\n",
    "# get X, Y for latest day\n",
    "latest_x, latest_y = load_processed_data_from_file(timestamp=latest_day, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage params\n",
    "num_pertubations=1000\n",
    "num_samples=1000\n",
    "quantile=0.99\n",
    "\n",
    "# calculate coverage of normal, normal vs lockdown, normal vs latest\n",
    "normal_coverage = percentage_coverage(\n",
    "    normal_model,\n",
    "    normal_x[:,0][:,np.newaxis],\n",
    "    normal_y,\n",
    "    num_pertubations=num_pertubations,\n",
    "    num_samples=num_samples,\n",
    "    quantile=quantile\n",
    ")\n",
    "normal_to_lockdown_coverage = percentage_coverage(\n",
    "    normal_model,\n",
    "    lockdown_x[:,0][:,np.newaxis],\n",
    "    lockdown_y,\n",
    "    num_pertubations=num_pertubations,\n",
    "    num_samples=num_samples,\n",
    "    quantile=quantile\n",
    ")\n",
    "normal_to_latest_coverage = percentage_coverage(\n",
    "    normal_model,\n",
    "    latest_x[:,0][:,np.newaxis],\n",
    "    latest_y,\n",
    "    num_pertubations=num_pertubations,\n",
    "    num_samples=num_samples,\n",
    "    quantile=quantile\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate data\n",
    "\n",
    "Hack the data to see how the percentage coverage is reacting.\n",
    "\n",
    "1. Take the first purple outlier where the intensity is high. For all outliers after this, set purple points to be blue. Calculate percentage coverage with new data.\n",
    "2. Take a purple point where the intensity is low and make it an outlier (e.g. increase it by $2\\sigma$). Set all other purple outliers and set them to be blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning\n",
    "\n",
    "1. Split a day into 6 hour bins.\n",
    "2. Calculate the percentage coverage for each bin\n",
    "3. The percentage coverage will now be a vector of length 4.\n",
    "\n",
    "> Question: should we do this per hour or for 6 hour bins (or both)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative log predicted likelihood (NLPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'poisson' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-516b14710c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ToDo: check this code from Virgi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpred_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'poisson' is not defined"
     ]
    }
   ],
   "source": [
    "# ToDo: check this code from Virgi\n",
    "np.sum(poisson.logpmf(true_counts, pred_counts))/pred_counts.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting metrics into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanair",
   "language": "python",
   "name": "cleanair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
