{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitcleanairconda15a7631f7c104f11bf0dbf211fe6f892",
   "display_name": "Python 3.7.6 64-bit ('cleanair': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "from cleanair.scoot import load_model_and_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpfp = \"./experiments\"  # root to filepaths directory\n",
    "figure_dir = os.path.join(xpfp, \"figures\"))\n",
    "\n",
    "\n",
    "Path(figure_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/models/N00_002e1/10Feb_16Feb/model.h5'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-468398ee7fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'N00/002e1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'10Feb_16Feb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/repos/clean-air-infrastructure/containers/cleanair/scoot/util.py\u001b[0m in \u001b[0;36mload_model_and_metadata\u001b[0;34m(scoot_id, date_range)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Load X and Y arrays to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/models/N00_002e1/10Feb_16Feb/model.h5'"
     ]
    }
   ],
   "source": [
    "detector_id = \"N00/002e1\"\n",
    "scoot_id = 0\n",
    "\n",
    "model0, X_arr, Y_arr, metadata = load_model_and_metadata(detector_id,'10Feb_16Feb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_counts = 'C0'\n",
    "label_counts = 'N'\n",
    "color_estimated_counts = 'red'\n",
    "label_estimated_counts = '$\\hat{N}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "sensor_df = normal_df_list[index]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=sensor_df['measurement_start_utc'], y=sensor_df['n_vehicles_in_interval'],\n",
    "                    mode='lines+markers',\n",
    "                    name='lines+markers')\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Timeseries of sensor {scoot_id}'.format(scoot_id=detector_list[index]),\n",
    "                xaxis_title=\"Datetime\",\n",
    "                yaxis_title=\"# of vechicles per hour\",\n",
    "                font=dict(\n",
    "                    size=16)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BUGGY\n",
    "## Computes percentage cover (see Virginia's pdf for details)\n",
    "def percentage_coverage(model,test_inputs,Ytest,quantile:int = 0.95, num_samples:int = 10,num_pertubations: int = 100):\n",
    "    # Number of times total counts were within 90th percentile\n",
    "    coverage_events = 0\n",
    "    \n",
    "    # Loop over pertubations\n",
    "    for i in range(num_pertubations):\n",
    "\n",
    "        # Change seed\n",
    "        np.random.seed(i)\n",
    "        \n",
    "        # Sample from latent function (intensity)\n",
    "        intensity_sample = np.exp(model.predict_f_samples(test_inputs,num_samples))\n",
    "        # Compute emprical distribution of counts\n",
    "        empirical_count_distribution = np.random.poisson(intensity_sample)\n",
    "        \n",
    "        # Total number of actual counts\n",
    "        total_counts = np.sum(Ytest)\n",
    "       \n",
    "        # Compute upper and lower quantiles from the empirical distribution of counts\n",
    "        upper_q = np.quantile(np.sum(samples[:,:,0],axis=1),quantile)\n",
    "        lower_q = np.quantile(np.sum(samples[:,:,0],axis=1),1-quantile)\n",
    "    \n",
    "        # Add 1 - if total counts are within quantile, 0 - otherwise\n",
    "        coverage_events += int((total_counts < upper_q) & (total_counts > lower_q))\n",
    "        binary = int((total_counts < upper_q) & (total_counts > lower_q)) # this is kept for debugging (remove afterwards)\n",
    "\n",
    "    return empirical_count_distribution, binary, total_counts, upper_q, lower_q # this is kept for debugging (remove afterwards)\n",
    "    return coverage_events/num_pertubations # this should be the output after debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_results(sensor_df, detector_id, model0, X_arr[scoot_id], num_samples=1000)"
   ]
  }
 ]
}